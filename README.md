# buildyourCrawler
构建你自己的爬虫小工具


这是一系列搜集网络信息的爬虫小工具，使用python3编写，使用requests和BeautifulSoup库，可以爬取指定网站的信息，并保存到本地文件中。


如果你想学习爬虫，或者想了解爬虫的基本原理，那么这个项目是一个很好的起点。你可以根据自己的需求，修改代码，添加新的功能，或者改进代码的性能。


请开始参考学习吧。


## 开源项目

- [requests](https://github.com/psf/requests)
- [BeautifulSoup](https://github.com/benjaminp/soupsieve)
- [python爬虫教程](https://github.com/wistbean/learn_python3_spider)利用 Scrapy 框架对 Github 用户和仓库信息进行爬取，图片利用管道下载。


[LeetCode](https://github.com/ProgramRipper/LeetCodeCN-Problem-Crawler)
爬取 LeetCode 题目描述，并存储为 markdown 或 txt 文件。支持指定状态、难度和语言的题目描述。

[电子书](https://github.com/xiejava1018/getbooks?tab=readme-ov-file)
python爬虫爬取电子书

[ Github 用户和仓库信息](https://github.com/KenZP/Github/tree/master)
利用 Scrapy 框架对 Github 用户和仓库信息进行爬取，图片利用管道下载。

[各大博客爬虫](https://github.com/Adj325/BlogCrawlers/tree/master)
- 51CTO blog.51cto.com
- CSDN blog.csdn.net
- 腾讯云 cloud.tencent.com
- 博客园 cnblogs.com
- 阿里云开发者社区 developer.aliyun.com
- 掘金 juejin.im
- 微信推文 mp.weixin.qq.com
- 开源中国 my.oschina.net
- 思否 segmentfault.com
- 脚本之家 www.jb51.net
- 简书 www.jianshu.com
- 知乎专栏 zhuanlan.zhihu.com
- 人人都是产品经理 www.woshipm.com


[v2ex.com](https://github.com/oldshensheep/v2ex_scrapy)一个爬取v2ex.com网站的爬虫

[知乎与v2ex](https://github.com/h2pl/pyspider)知乎爬虫和v2ex爬虫的实现

